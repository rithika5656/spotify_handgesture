"""
COMPLETE INSTALLATION AND SETUP GUIDE
Step-by-step instructions for Windows, Linux, and macOS
"""

# ============================================================================
#                        INSTALLATION GUIDE
# ============================================================================

SETUP_GUIDE = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  GESTURE-CONTROLLED MEDIA PLAYER - SETUP GUIDE
                                                
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT REQUIREMENTS:
- Python 3.8 or higher
- Webcam (built-in or USB)
- 4GB RAM (8GB recommended)
- Windows/Linux/macOS

ESTIMATED TIME: 10-15 minutes

============================================================================
STEP 1: VERIFY PYTHON INSTALLATION
============================================================================

Open Command Prompt/PowerShell/Terminal and run:

    python --version

If this shows "Python 3.8+" then proceed.
If not, download from https://www.python.org/downloads/

âš ï¸  IMPORTANT for Windows: During installation, CHECK "Add Python to PATH"

============================================================================
STEP 2: NAVIGATE TO PROJECT DIRECTORY
============================================================================

Windows (PowerShell):
    cd "c:\\Users\\rithi\\OneDrive\\Desktop\\HAND GESTURE"

Linux/macOS (Terminal):
    cd ~/Desktop/"HAND GESTURE"

Verify you see:
    - modules/
    - data/
    - collect_data.py
    - train_model.py
    - etc.

============================================================================
STEP 3: CREATE VIRTUAL ENVIRONMENT
============================================================================

Windows (PowerShell):
    python -m venv venv
    .\\venv\\Scripts\\activate

Linux/macOS (Terminal):
    python3 -m venv venv
    source venv/bin/activate

Expected: You should see (venv) prefix in your terminal

============================================================================
STEP 4: UPGRADE PIP
============================================================================

    python -m pip install --upgrade pip

This ensures you have the latest package installer.

============================================================================
STEP 5: INSTALL DEPENDENCIES
============================================================================

    pip install -r requirements.txt

This will install:
    âœ“ opencv-python
    âœ“ mediapipe
    âœ“ numpy
    âœ“ scikit-learn
    âœ“ joblib
    âœ“ pycaw (Windows only for volume control)
    âœ“ pyautogui

â±ï¸  This may take 3-5 minutes depending on your internet speed.

============================================================================
STEP 6: VERIFY INSTALLATION
============================================================================

Run the test script:
    python test_modules.py

This will test:
    âœ“ Camera detection
    âœ“ MediaPipe hand detection
    âœ“ Feature extraction

If all tests pass, you're ready to proceed!

============================================================================
STEP 7: COLLECT TRAINING DATA
============================================================================

Run:
    python collect_data.py

Instructions:
    1. Position your hand in front of the camera
    2. Press SPACE to capture frames for each gesture
    3. Collect at least 50 samples per gesture
    4. Total: ~250 samples for 5 gestures
    5. Take ~10-15 minutes

GESTURES TO COLLECT:
    âœ‹ PALM        - Open hand (all fingers extended)
    âœŠ FIST        - Closed fist (all fingers folded)
    ğŸ¤ PINCH       - Thumb and index finger together
    ğŸ‘‰ POINT       - Index finger pointing up
    âœŒ  V_SIGN      - Peace sign (two fingers)

Tips:
    â€¢ Collect in good lighting
    â€¢ Vary hand distance from camera (30-50cm)
    â€¢ Vary hand orientation (different angles)
    â€¢ Try different backgrounds
    â€¢ The more diverse, the better the accuracy!

============================================================================
STEP 8: TRAIN THE MODEL
============================================================================

Run:
    python train_model.py

This will:
    âœ“ Load your collected data
    âœ“ Train Random Forest classifier
    âœ“ Evaluate accuracy
    âœ“ Save the model

Expected output:
    âœ“ Loaded dataset: 250 samples, 8 features
    âœ“ Classes: 5
    Training accuracy: ~95%
    Test accuracy: ~90%

â±ï¸  Training takes ~30 seconds

============================================================================
STEP 9: TEST REAL-TIME CONTROL
============================================================================

Run:
    python main_pipeline.py

Controls:
    âœ“ Show your hand and see it detected
    âœ“ Different gestures should trigger different actions
    âœ“ Watch volume bar change
    âœ“ Press 'Q' to quit
    âœ“ Press 'S' to see settings

First run checklist:
    â˜ Hand is detected (green text appears)
    â˜ Gesture name is shown
    â˜ Confidence score is displayed
    â˜ Volume level is shown
    â˜ Actions are executed on your system

============================================================================
TROUBLESHOOTING
============================================================================

âŒ Camera not detected:
   â†’ Check if webcam is working (try Skype, Discord)
   â†’ Grant camera permissions to Python
   â†’ Restart the application

âŒ No gestures recognized:
   â†’ Collect more training data (100+ per gesture)
   â†’ Ensure varied lighting conditions
   â†’ Check confidence threshold in config.py

âŒ Volume control not working:
   â†’ Windows: Run with administrator privileges
   â†’ Linux: Install audio library
   â†’ macOS: Check system permissions

âŒ ImportError for mediapipe:
   â†’ pip uninstall mediapipe
   â†’ pip install mediapipe --upgrade

âŒ "Module not found" errors:
   â†’ Make sure venv is activated
   â†’ Run from project root directory
   â†’ Check requirements.txt is in correct location

============================================================================
FILE STRUCTURE AFTER SETUP
============================================================================

After completing all steps, your directory should look like:

    HAND GESTURE/
    â”œâ”€â”€ modules/
    â”‚   â”œâ”€â”€ hand_detection.py
    â”‚   â”œâ”€â”€ feature_extraction.py
    â”‚   â”œâ”€â”€ gesture_classifier.py
    â”‚   â”œâ”€â”€ action_mapper.py
    â”‚   â””â”€â”€ media_controller.py
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ 0_PALM/ (with .npy files)
    â”‚   â”œâ”€â”€ 1_FIST/ (with .npy files)
    â”‚   â”œâ”€â”€ 2_PINCH/ (with .npy files)
    â”‚   â”œâ”€â”€ 3_POINT/ (with .npy files)
    â”‚   â”œâ”€â”€ 4_V_SIGN/ (with .npy files)
    â”‚   â”œâ”€â”€ gesture_model_random_forest.pkl âœ“
    â”‚   â””â”€â”€ gesture_model_random_forest_scaler.pkl âœ“
    â”œâ”€â”€ venv/
    â”œâ”€â”€ collect_data.py
    â”œâ”€â”€ train_model.py
    â”œâ”€â”€ main_pipeline.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ ...other files...

============================================================================
QUICK COMMANDS SUMMARY
============================================================================

Setup (first time only):
    python -m venv venv
    .\\venv\\Scripts\\activate          # Windows
    source venv/bin/activate           # Linux/macOS
    pip install -r requirements.txt

Always activate virtual environment before running:
    .\\venv\\Scripts\\activate          # Windows
    source venv/bin/activate           # Linux/macOS

Run setup wizard:
    python quick_start.py

Test components:
    python test_modules.py

Collect training data:
    python collect_data.py

Train model:
    python train_model.py

Run gesture control:
    python main_pipeline.py

Deactivate virtual environment (when done):
    deactivate

============================================================================
NEXT STEPS
============================================================================

1. âœ… Install dependencies
2. âœ… Verify installation
3. âœ… Collect training data
4. âœ… Train the model
5. âœ… Run real-time control
6. ğŸ“– Read README.md for advanced usage
7. ğŸ”§ Customize in config.py
8. ğŸ“Š Improve model with more data

============================================================================
SUPPORT
============================================================================

If you encounter issues:

1. Check the error message carefully
2. Ensure Python 3.8+
3. Verify all dependencies installed
4. Check if webcam is working
5. Try running test_modules.py
6. Review ARCHITECTURE.md for technical details

============================================================================

Ready to proceed? Run:

    python collect_data.py

Good luck! ğŸš€
"""

if __name__ == "__main__":
    print(SETUP_GUIDE)
